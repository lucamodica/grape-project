{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model train\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Reddit, Amazon\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.functional import F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import NeighborSampler, NeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, understand and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_data = pd.read_parquet('data/amazon_product_data_word2vec.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load('data/amazon_product_data.pt')\n",
    "data.num_classes = data.y.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts = node_data['main_category'].value_counts()\n",
    "\n",
    "# # plot a bar chart of the main categories\n",
    "# plt.figure(figsize=(20, 8))\n",
    "# plt.bar(value_counts.index, value_counts.values)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.utils import to_networkx\n",
    "\n",
    "# G = to_networkx(data, to_undirected=True)\n",
    "# visualize_graph(G, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data Data(x=[863130, 100], edge_index=[2, 815222], y=[863130], num_classes=27)\n",
      "num nodes 863130\n",
      "Num edges 815222\n",
      "num node features 100\n",
      "is undirected False\n",
      "is directed True\n",
      "num edge features 0\n",
      "num classes 27\n"
     ]
    }
   ],
   "source": [
    "print(\"data\", data)\n",
    "print(\"num nodes\", data.num_nodes)\n",
    "print(\"Num edges\", data.num_edges)\n",
    "print(\"num node features\", data.num_node_features)\n",
    "print(\"is undirected\", data.is_undirected())\n",
    "print(\"is directed\", data.is_directed())\n",
    "print(\"num edge features\", data.num_edge_features)\n",
    "print('num classes', data.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_data_split_masks(data, train_ratio=0.8, val_ratio=0.1):\n",
    "#   # Total number of nodes\n",
    "#   num_nodes = data.num_nodes\n",
    "\n",
    "#   # Randomly permute the node indices\n",
    "#   perm = torch.randperm(num_nodes)\n",
    "\n",
    "#   # Calculate split sizes\n",
    "#   train_size = int(train_ratio * num_nodes)\n",
    "#   val_size = int(val_ratio * num_nodes)\n",
    "#   test_size = num_nodes - train_size - val_size\n",
    "\n",
    "#   # Create masks for train, validation, and test\n",
    "#   train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "#   val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "#   test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "#   # Assign masks\n",
    "#   train_mask[perm[:train_size]] = True\n",
    "#   val_mask[perm[train_size:train_size + val_size]] = True\n",
    "#   test_mask[perm[train_size + val_size:]] = True\n",
    "\n",
    "#   # Assign masks to the data object\n",
    "#   data.train_mask = train_mask\n",
    "#   data.val_mask = val_mask\n",
    "#   data.test_mask = test_mask\n",
    "  \n",
    "#   return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def create_masks(data, num_nodes, train_ratio, val_ratio):\n",
    "    # Generate and shuffle indices\n",
    "    indices = list(range(num_nodes))\n",
    "    # shuflle with numpy rng to get reproducibility\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Create masks\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    # Set proportions for train, val, and test\n",
    "    train_end = int(train_ratio * num_nodes)\n",
    "    val_end = train_end + int(val_ratio * num_nodes)\n",
    "\n",
    "    train_mask[indices[:train_end]] = True\n",
    "    val_mask[indices[train_end:val_end]] = True\n",
    "    test_mask[indices[val_end:]] = True\n",
    "\n",
    "    # Assign the custom masks to the dataset\n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "\n",
    "\n",
    "def train_test_split_graph(data, train_ratio, val_ratio):\n",
    "    num_nodes = data.num_nodes\n",
    "\n",
    "    # Call the function to create masks\n",
    "    create_masks(data, num_nodes, train_ratio, val_ratio)\n",
    "\n",
    "    # Step 5: Create train, validation, and test node indices based on the masks\n",
    "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
    "    val_idx = data.val_mask.nonzero(as_tuple=False).view(-1)\n",
    "    test_idx = data.test_mask.nonzero(as_tuple=False).view(-1)\n",
    "\n",
    "    # create the data loaders\n",
    "    train_loader = NeighborLoader(data,\n",
    "      # Sample 30 neighbors for each node for 2 iterations\n",
    "      num_neighbors=[30] * 2,\n",
    "      batch_size=128,\n",
    "      input_nodes=train_idx,\n",
    "    )\n",
    "    val_loader = NeighborLoader(data,\n",
    "      num_neighbors=[30] * 2,\n",
    "      batch_size=128,\n",
    "      input_nodes=val_idx,\n",
    "    )\n",
    "    test_loader = NeighborLoader(data,\n",
    "      num_neighbors=[30] * 2,\n",
    "      batch_size=128,\n",
    "      input_nodes=test_idx,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.linear2 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = F.relu(h)\n",
    "        x = self.linear1(h)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.linear1 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.linear2 = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = F.relu(h)\n",
    "        x = self.linear1(h)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_epoch(model, optimizer, loader, device):\n",
    "#     \"\"\"Train the model for one epoch\"\"\"\n",
    "#     model.train()\n",
    "    \n",
    "#     b_losses = np.empty(len(loader))\n",
    "#     b_accuracies = np.empty(len(loader))\n",
    "\n",
    "#     for batch in loader:\n",
    "#       batch.to(device)\n",
    "#       optimizer.zero_grad()\n",
    "#       out = model(batch.x, batch.edge_index)\n",
    "#       loss = F.nll_loss(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "#       loss.backward()\n",
    "#       optimizer.step()\n",
    "      \n",
    "#       b_losses = np.append(b_losses, loss.item())\n",
    "      \n",
    "#       b_acc = (out[batch.train_mask].argmax(dim=1) == batch.y[batch.train_mask]).sum().item() / batch.train_mask.sum().item()\n",
    "#       b_accuracies = np.append(b_accuracies, b_acc)\n",
    "      \n",
    "#     loss = np.mean(b_losses)\n",
    "#     acc = np.mean(b_accuracies)\n",
    "#     return loss, acc\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def evaluate(model, loader, mask_name, device):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "    \n",
    "#     for batch in loader:\n",
    "#         batch.to(device)\n",
    "#         out = model(batch.x, batch.edge_index)\n",
    "#         pred = out.argmax(dim=1)\n",
    "#         mask = getattr(batch, mask_name)\n",
    "#         correct += pred[mask].eq(batch.y[mask]).sum().item()\n",
    "        \n",
    "#     total = sum(getattr(batch, mask_name).sum().item() for batch in loader)\n",
    "#     return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loader, device):\n",
    "    \"\"\"Train the model for one epoch using NeighborSampler mini-batches.\"\"\"\n",
    "    model.train()\n",
    "    b_losses = []\n",
    "    b_accuracies = []\n",
    "\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch.to(device)\n",
    "        \n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        loss = F.nll_loss(out, batch.y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        b_losses.append(loss.item())\n",
    "        b_acc = (out.argmax(dim=1) == batch.y).sum().item() / batch.y.size(0)\n",
    "        b_accuracies.append(b_acc)\n",
    "        \n",
    "    return np.mean(b_losses), np.mean(b_accuracies)\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device, data):\n",
    "    \"\"\"Evaluate the model on the validation or test set using NeighborSampler mini-batches.\"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch_size, n_id, adjs in data_loader:\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "\n",
    "        # Compute predictions for all nodes in the mini-batch\n",
    "        x_input = data.x[n_id].to(device)\n",
    "        out = model(x_input, adjs[0].edge_index)\n",
    "\n",
    "        # Get predictions only for the first `batch_size` target nodes\n",
    "        pred = out[:batch_size].max(dim=1)[1]\n",
    "\n",
    "        # Compare with the actual labels of the target nodes\n",
    "        total_correct += (pred ==\n",
    "                          data.y[n_id[:batch_size]].to(device)).sum().item()\n",
    "\n",
    "    # Calculate accuracy based on the number of target nodes in the entire set\n",
    "    return total_correct / len(data_loader.dataset)\n",
    "  \n",
    "# compute confusion matrix\n",
    "def confusion_matrixx(model, loader, device, data):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for batch_size, n_id, adjs in loader:\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "        x_input = data.x[n_id].to(device)\n",
    "        out = model(x_input, adjs[0].edge_index)\n",
    "        pred = out[:batch_size].max(dim=1)[1]\n",
    "\n",
    "        y_true.append(data.y[n_id[:batch_size]].to(device))\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 2.5478, Train Acc: 0.1630\n",
      "Epoch: 02, Loss: 2.5568, Train Acc: 0.1657\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m---> 15\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# val_acc = evaluate(model, val_loader, device, data)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, optimizer, loader, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(out, batch\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[23], line 32\u001b[0m, in \u001b[0;36mGAT.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     30\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\n\u001b[1;32m     31\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(h)\n\u001b[0;32m---> 32\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m h \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(h)\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(h)\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch_geometric/nn/conv/gat_conv.py:366\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    362\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_updater(edge_index, alpha\u001b[38;5;241m=\u001b[39malpha, edge_attr\u001b[38;5;241m=\u001b[39medge_attr,\n\u001b[1;32m    363\u001b[0m                           size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m    365\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat:\n\u001b[1;32m    369\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n",
      "File \u001b[0;32m/var/folders/0v/j168s2s91bxf0vr_r7rn3m_c0000gn/T/torch_geometric.nn.conv.gat_conv_GATConv_propagate_mm_09f0r.py:212\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, alpha, size)\u001b[0m\n\u001b[1;32m    203\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    204\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[1;32m    205\u001b[0m                 alpha\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39malpha,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    209\u001b[0m             )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    579\u001b[0m     inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    583\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    584\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch_geometric/experimental.py:117\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_dynamic_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[0m, in \u001b[0;36mSumAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rigged/lib/python3.10/site-packages/torch_geometric/utils/_scatter.py:75\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "\n",
    "\n",
    "train_loader, val_loader, _ = train_test_split_graph(data, train_ratio, val_ratio)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = GAT(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, 4):\n",
    "    loss, acc = train_epoch(model, optimizer, train_loader, device)\n",
    "    # val_acc = evaluate(model, val_loader, device, data)\n",
    "    # print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train Acc: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrixx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_true\u001b[38;5;241m.\u001b[39mcpu(), y_pred\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "Cell \u001b[0;32mIn[25], line 55\u001b[0m, in \u001b[0;36mconfusion_matrixx\u001b[0;34m(model, loader, device, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m y_true \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     53\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size, n_id, adjs \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     56\u001b[0m     adjs \u001b[38;5;241m=\u001b[39m [adj\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m adj \u001b[38;5;129;01min\u001b[39;00m adjs]\n\u001b[1;32m     57\u001b[0m     x_input \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx[n_id]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_true, y_pred = confusion_matrixx(model, val_loader, device, data)\n",
    "cm = confusion_matrix(y_true.cpu(), y_pred.cpu())\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rigged",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

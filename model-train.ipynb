{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "#import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "from models import *\n",
    "from umap import UMAP\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read, understand and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58286/2857709582.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load('data/amazon_product_data_sum.pt')\n"
     ]
    }
   ],
   "source": [
    "# node_data = pd.read_parquet('data/amazon_product_data_word2vec.parquet')\n",
    "data = torch.load('data/amazon_product_data_sum.pt')\n",
    "data.num_classes = data.y.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data Data(x=[729819, 300], edge_index=[2, 680548], y=[729819], num_classes=10)\n",
      "num nodes 729819\n",
      "Num edges 680548\n",
      "num node features 300\n",
      "is undirected False\n",
      "is directed True\n",
      "num edge features 0\n",
      "num classes 10\n"
     ]
    }
   ],
   "source": [
    "print(\"data\", data)\n",
    "print(\"num nodes\", data.num_nodes)\n",
    "print(\"Num edges\", data.num_edges)\n",
    "print(\"num node features\", data.num_node_features)\n",
    "print(\"is undirected\", data.is_undirected())\n",
    "print(\"is directed\", data.is_directed())\n",
    "print(\"num edge features\", data.num_edge_features)\n",
    "print('num classes', data.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts = node_data['main_category'].value_counts()\n",
    "\n",
    "# # plot a bar chart of the main categories\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.bar(value_counts.index, value_counts.values)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title('Main Category Distribution')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(h, color):\n",
    "    z = UMAP(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize(h, color):\n",
    "#     z = UMAP(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.xticks([])\n",
    "#     plt.yticks([])\n",
    "\n",
    "#     plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(data, train_ratio, val_ratio):\n",
    "  num_nodes = data.num_nodes\n",
    "  indices = list(range(num_nodes))\n",
    "  np.random.shuffle(indices)\n",
    "  \n",
    "  # Create masks\n",
    "  train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "  val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "  test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "  \n",
    "  # Set proportions for train, val, and test\n",
    "  train_end = int(train_ratio * num_nodes)\n",
    "  val_end = train_end + int(val_ratio * num_nodes)\n",
    "  train_mask[indices[:train_end]] = True\n",
    "  val_mask[indices[train_end:val_end]] = True\n",
    "  test_mask[indices[val_end:]] = True\n",
    "  \n",
    "  # Assign the custom masks to the dataset\n",
    "  data.train_mask = train_mask\n",
    "  data.val_mask = val_mask\n",
    "  data.test_mask = test_mask\n",
    "\n",
    "\n",
    "def train_test_split_graph(data: Data, train_ratio: float, val_ratio: float, batch_size: int):\n",
    "    \"\"\"\n",
    "    Split the graph data into train, validation, and test sets\n",
    "    :param data: The graph data\n",
    "    :param train_ratio: The ratio of the training set\n",
    "    :param val_ratio: The ratio of the validation set\n",
    "    :param batch_size: The batch size\n",
    "    \n",
    "    :return: The train, validation, and test data loaders\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the function to create masks\n",
    "    create_masks(data, train_ratio, val_ratio)\n",
    "\n",
    "    # train, validation, and test node indices based on the masks\n",
    "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
    "    val_idx = data.val_mask.nonzero(as_tuple=False).view(-1)\n",
    "    test_idx = data.test_mask.nonzero(as_tuple=False).view(-1)\n",
    "    \n",
    "    def create_data_loader(data, indices):\n",
    "        return DataLoader(data[indices], batch_size=batch_size, shuffle=True)\n",
    "      \n",
    "    def create_neighbor_loader(data, indices, batch_size=batch_size):\n",
    "        return NeighborLoader(data, num_neighbors=[30] * 2, batch_size=batch_size, input_nodes=indices)\n",
    "\n",
    "    # create the data loaders\n",
    "    train_loader = create_neighbor_loader(data, train_idx)\n",
    "    val_loader = create_neighbor_loader(data, val_idx, batch_size=4096*2)\n",
    "    test_loader = create_neighbor_loader(data, test_idx)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    correct = (predictions.argmax(dim=1) == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def f1(predictions, labels):\n",
    "    preds = predictions.argmax(dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    return f1_score(labels, preds, average='weighted')\n",
    "  \n",
    "def balanced_accuracy(predictions, labels):\n",
    "    preds = predictions.argmax(dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    return balanced_accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size 72981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucamodica/mambaforge/envs/rigged/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    }
   ],
   "source": [
    "# print the size of the validation set\n",
    "train_loader, val_loader, test_loader = train_test_split_graph(data, 0.8, 0.1, 4096)\n",
    "print(\"Validation set size\", len(val_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loss_fn, train_loader, device, metrics):\n",
    "    model.train()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    losses = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        out, h = model(batch.x, batch.edge_index)  # Receive only one output\n",
    "        loss = loss_fn(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        all_preds.append(out.detach().cpu())\n",
    "        all_labels.append(batch.y.detach().cpu())\n",
    "        \n",
    "    # Concatenate all predictions and labels\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Compute metrics on the entire dataset\n",
    "    avg_metrics = {metric_name: metric_fn(all_preds, all_labels) \n",
    "                  for metric_name, metric_fn in metrics.items()}\n",
    "    avg_loss = np.mean(losses)\n",
    "\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loss_fn, val_loader, device, metrics):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    losses = []\n",
    "\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        out, h = model(batch.x, batch.edge_index)  # Receive only one output\n",
    "        loss = loss_fn(out, batch.y)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        all_preds.append(out.detach().cpu())\n",
    "        all_labels.append(batch.y.detach().cpu())\n",
    "        \n",
    "    # with torch.no_grad():\n",
    "    #   _, h = model(val_loader.data.x, val_loader.data.edge_index)\n",
    "    #   visualize(h, val_loader.data.y)\n",
    "\n",
    "    # Concatenate all predictions and labels\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Compute metrics on the entire dataset\n",
    "    avg_metrics = {metric_name: metric_fn(all_preds, all_labels) \n",
    "                  for metric_name, metric_fn in metrics.items()}\n",
    "    avg_loss = np.mean(losses)\n",
    "\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "def training_loop(model, optimizer, loss_fn, train_loader, val_loader, num_epochs, device, metrics):\n",
    "    print(\"Starting training\")\n",
    "    train_losses, val_losses = [], []\n",
    "    train_metrics_history = {metric_name: [] for metric_name in metrics}\n",
    "    val_metrics_history = {metric_name: [] for metric_name in metrics}\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Training\n",
    "        train_loss, train_metrics = train_epoch(\n",
    "            model, optimizer, loss_fn, train_loader, device, metrics)\n",
    "        # Validation\n",
    "        val_loss, val_metrics = validate(\n",
    "            model, loss_fn, val_loader, device, metrics)\n",
    "        \n",
    "        # Logging results\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        for metric_name in metrics:\n",
    "            train_metrics_history[metric_name].append(train_metrics[metric_name])\n",
    "            val_metrics_history[metric_name].append(val_metrics[metric_name])\n",
    "\n",
    "        # Print metrics\n",
    "        metrics_str = ', '.join(\n",
    "            [f'{metric_name}: {train_metrics[metric_name]:.3f} (train), {val_metrics[metric_name]:.3f} (val)'\n",
    "             for metric_name in metrics])\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs}: \"\n",
    "            f\"Loss: {train_loss:.3f} (train), {val_loss:.3f} (val), \"\n",
    "            f\"{metrics_str}\"\n",
    "        )\n",
    "\n",
    "    return model, train_losses, val_losses, train_metrics_history, val_metrics_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "learning_rate = 0.01  \n",
    "batch_size = 64\n",
    "  \n",
    "train_loader, val_loader, test_loader = train_test_split_graph(\n",
    "      data, train_ratio, val_ratio, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_experiment(model, train_loader, val_loader):\n",
    "  print(model.__class__.__name__)\n",
    "  \n",
    "  optimizer = torch.optim.Adam(\n",
    "      model.parameters(), lr=learning_rate)\n",
    "  \n",
    "  loss_fn = torch.nn.CrossEntropyLoss()\n",
    "  \n",
    "  metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'f1': f1,\n",
    "    'balanced_accuracy': balanced_accuracy,\n",
    "  }\n",
    "  \n",
    "  # Train the model\n",
    "  model, train_losses, val_losses, train_metrics_history, val_metrics_history = training_loop(\n",
    "    model, optimizer, loss_fn, train_loader, val_loader, num_epochs=10, device=device, metrics=metrics\n",
    "  )\n",
    "  \n",
    "  return {\n",
    "    'model': model,\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_metrics_history': train_metrics_history,\n",
    "    'val_metrics_history': val_metrics_history\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes).to(device)\n",
    "gat = GAT(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes, num_heads=8)\n",
    "gin = GIN(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes)\n",
    "gsage = GraphSAGE(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT\n",
      "Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucamodica/mambaforge/envs/rigged/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2480: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Loss: 0.511 (train), 0.236 (val), accuracy: 0.832 (train), 0.930 (val), f1: 0.832 (train), 0.930 (val), balanced_accuracy: 0.824 (train), 0.927 (val)\n",
      "Epoch 2/10: Loss: 0.157 (train), 0.150 (val), accuracy: 0.956 (train), 0.957 (val), f1: 0.956 (train), 0.957 (val), balanced_accuracy: 0.954 (train), 0.956 (val)\n",
      "Epoch 3/10: Loss: 0.109 (train), 0.125 (val), accuracy: 0.970 (train), 0.965 (val), f1: 0.970 (train), 0.965 (val), balanced_accuracy: 0.969 (train), 0.964 (val)\n",
      "Epoch 4/10: Loss: 0.092 (train), 0.131 (val), accuracy: 0.975 (train), 0.963 (val), f1: 0.975 (train), 0.963 (val), balanced_accuracy: 0.974 (train), 0.961 (val)\n",
      "Epoch 5/10: Loss: 0.082 (train), 0.108 (val), accuracy: 0.978 (train), 0.970 (val), f1: 0.978 (train), 0.970 (val), balanced_accuracy: 0.977 (train), 0.969 (val)\n",
      "Epoch 6/10: Loss: 0.075 (train), 0.123 (val), accuracy: 0.979 (train), 0.965 (val), f1: 0.979 (train), 0.965 (val), balanced_accuracy: 0.979 (train), 0.965 (val)\n",
      "Epoch 7/10: Loss: 0.071 (train), 0.103 (val), accuracy: 0.980 (train), 0.972 (val), f1: 0.980 (train), 0.972 (val), balanced_accuracy: 0.980 (train), 0.971 (val)\n",
      "Epoch 8/10: Loss: 0.068 (train), 0.098 (val), accuracy: 0.981 (train), 0.973 (val), f1: 0.981 (train), 0.973 (val), balanced_accuracy: 0.981 (train), 0.972 (val)\n",
      "Epoch 9/10: Loss: 0.065 (train), 0.092 (val), accuracy: 0.982 (train), 0.975 (val), f1: 0.982 (train), 0.975 (val), balanced_accuracy: 0.981 (train), 0.974 (val)\n",
      "Epoch 10/10: Loss: 0.063 (train), 0.101 (val), accuracy: 0.983 (train), 0.973 (val), f1: 0.983 (train), 0.973 (val), balanced_accuracy: 0.982 (train), 0.973 (val)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "gcn_results = gnn_experiment(gat, train_loader, val_loader)\n",
    "# gat_results = gnn_experiment(gat, train_loader, val_loader)\n",
    "#gnn_experiment(gin, train_loader, val_loader)\n",
    "#gnn_experiment(gsage, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the metrics in a single plot\n",
    "def plot_metrics(results):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    for ax, (metric_name, metric_values) in zip(axs, results['train_metrics_history'].items()):\n",
    "        ax.plot(metric_values, label='train')\n",
    "        ax.plot(results['val_metrics_history'][metric_name], label='val')\n",
    "        ax.set_title(metric_name)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gnn_experiment(model, train_loader, val_loader):\n",
    "  \n",
    "#   optimizer = torch.optim.Adam(\n",
    "#       model.parameters(), lr=learning_rate)\n",
    "  \n",
    "#   loss_fn = torch.nn.CrossEntropyLoss()\n",
    "  \n",
    "#   metrics = {\n",
    "#     'accuracy': accuracy,\n",
    "#     'f1': f1,\n",
    "#     'balanced_accuracy': balanced_accuracy,\n",
    "#   }\n",
    "  \n",
    "#   # Train the model\n",
    "#   model, train_losses, val_losses, train_metrics_history, val_metrics_history = training_loop(\n",
    "#     model, optimizer, loss_fn, train_loader, val_loader, num_epochs=1, device=device, metrics=metrics\n",
    "#   )\n",
    "  \n",
    "#   return {\n",
    "#     'model': model,\n",
    "#     'train_losses': train_losses,\n",
    "#     'val_losses': val_losses,\n",
    "#     'train_metrics_history': train_metrics_history,\n",
    "#     'val_metrics_history': val_metrics_history\n",
    "#   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcn = GCN(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes).to(device)\n",
    "# #gat = GAT(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes, num_heads=8)\n",
    "# #gin = GIN(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes)\n",
    "# #gsage = GraphSAGE(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the models and get the results\n",
    "# #for model in [gcn, gat, gin, gsage]:\n",
    "# results = gnn_experiment(gcn, train_loader, val_loader) \n",
    "#  # torch.save(results, f'{model.__class__.__name__}_results.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # put all the results in a dataframe and display it as a table where it is easy to compare the models\n",
    "# results = []\n",
    "\n",
    "# for model in [gcn, gat, gin, gsage]:\n",
    "#   model_name = model.__class__.__name__\n",
    "#   results.append(torch.load(f'output/{model_name}_results.pt'))\n",
    "  \n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df['model'] = ['GCN', 'GAT', 'GIN', 'GraphSAGE']\n",
    "# results_df = results_df.set_index('model')\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(predictions, labels):\n",
    "    # visualize the confusion matrix with dusplay matrix from sklearn\n",
    "    \n",
    "    preds = predictions.argmax(dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argmax() got an unexpected keyword argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test the confusion matrix with the GCN results\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgcn_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 6\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(predictions, labels)\u001b[0m\n\u001b[1;32m      4\u001b[0m preds \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 6\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      8\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(predictions, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(predictions, labels):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# visualize the confusion matrix with dusplay matrix from sklearn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      5\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      6\u001b[0m     cm \u001b[38;5;241m=\u001b[39m confusion_matrix(labels, preds)\n",
      "\u001b[0;31mTypeError\u001b[0m: argmax() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": [
    "# test the confusion matrix with the GCN results\n",
    "confusion_matrix(gcn_results['model'](data.x, data.edge_index)[0], data.y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rigged",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

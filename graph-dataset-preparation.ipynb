{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph dataset preparation for PyTorch Geometric\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os.path as osp\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url, Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the embedded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_parquet('data/amazon_product_data_word2vec.parquet')\n",
    "edges = pd.read_parquet('data/amazon_product_edges_filtered.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193269/2758267631.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  node_features = torch.tensor(node_features, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[863130, 100], edge_index=[2, 815222])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def create_node_features(nodes, method='concat'):\n",
    "    \"\"\"\n",
    "    Creates node features by combining embeddings using the specified method.\n",
    "\n",
    "    :param nodes: A dictionary containing node embeddings.\n",
    "    :param method: The method to combine embeddings ('concat' or 'sum').\n",
    "    :return: A tensor of node features.\n",
    "    \"\"\"\n",
    "    node_features = []\n",
    "    for i in range(len(nodes['asin'])):\n",
    "        # Extract embeddings for the current node\n",
    "        embeddings = [\n",
    "            torch.tensor(nodes['title_embedding'][i], dtype=torch.float),\n",
    "            torch.tensor(nodes['brand_embedding'][i], dtype=torch.float),\n",
    "            torch.tensor(nodes['description_embedding'][i], dtype=torch.float),\n",
    "            torch.tensor(nodes['categories_embedding'][i], dtype=torch.float)\n",
    "        ]\n",
    "        if method == 'concat':\n",
    "            # Concatenate embeddings\n",
    "            features = torch.cat(embeddings, dim=0)\n",
    "        elif method == 'sum':\n",
    "            # Sum embeddings element-wise\n",
    "            features = sum(embeddings)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown fusion method: {method}\")\n",
    "        node_features.append(features)\n",
    "    # Stack the features into a tensor\n",
    "    node_features = torch.stack(node_features, dim=0)\n",
    "    return node_features\n",
    "\n",
    "def create_edge_index(nodes, edges):\n",
    "    \"\"\"\n",
    "    Creates the edge index tensor for the graph.\n",
    "\n",
    "    :param nodes: A dictionary containing node information.\n",
    "    :param edges: A dictionary containing edge information.\n",
    "    :return: An edge index tensor.\n",
    "    \"\"\"\n",
    "    # Create node index mapping\n",
    "    asin_to_index = {asin: i for i, asin in enumerate(nodes['asin'])}\n",
    "    # Create edge index\n",
    "    edge_index_list = []\n",
    "    for i in range(len(edges['from_asin'])):\n",
    "        source = asin_to_index[edges['from_asin'][i]]\n",
    "        target = asin_to_index[edges['to_asin'][i]]\n",
    "        edge_index_list.append([source, target])\n",
    "    edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "    return edge_index\n",
    "\n",
    "def create_labels(nodes):\n",
    "    \"\"\"\n",
    "    Encodes the node labels using LabelEncoder.\n",
    "\n",
    "    :param nodes: A dictionary containing node information.\n",
    "    :return: A tensor of labels.\n",
    "    \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(nodes['main_category'])\n",
    "    labels = torch.tensor(y, dtype=torch.long)\n",
    "    return labels\n",
    "\n",
    "def create_and_save_graph_data(nodes, edges, fusion_method, filename):\n",
    "    \"\"\"\n",
    "    Creates the graph data using the specified fusion method and saves it to a file.\n",
    "\n",
    "    :param nodes: A dictionary containing node information.\n",
    "    :param edges: A dictionary containing edge information.\n",
    "    :param fusion_method: The method to combine embeddings ('concat' or 'sum').\n",
    "    :param filename: The filename to save the graph data.\n",
    "    \"\"\"\n",
    "    # Create node features\n",
    "    node_features = create_node_features(nodes, method=fusion_method)\n",
    "    # Create edge index\n",
    "    edge_index = create_edge_index(nodes, edges)\n",
    "    # Create labels\n",
    "    labels = create_labels(nodes)\n",
    "    # Create the graph data object\n",
    "    data = Data(x=node_features, edge_index=edge_index, y=labels)\n",
    "    # Save the data to a file\n",
    "    torch.save(data, filename)\n",
    "    # Print information\n",
    "    print(f\"Data saved to {filename}\")\n",
    "    print(f\"Node feature size for method '{fusion_method}':\", data.x[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and save data with concatenation\n",
    "create_and_save_graph_data(\n",
    "    nodes, edges, fusion_method='concat', filename='data/amazon_product_data_concat.pt'\n",
    ")\n",
    "\n",
    "# Create and save data with summing\n",
    "create_and_save_graph_data(\n",
    "    nodes, edges, fusion_method='sum', filename='data/amazon_product_data_sum.pt'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rigged",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Reddit, Amazon\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import random\n",
    "from torch.functional import F\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from models import *\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Amazon dataset\n",
    "amazon_computers_dataset = Amazon(root='data/Amazon', name='Computers')\n",
    "data = amazon_computers_dataset[0]\n",
    "data.num_classes = data.y.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print info about the dataset\n",
    "print(\"data\", data)\n",
    "print(\"num nodes\", data.num_nodes)\n",
    "print(\"Num edges\", data.num_edges)\n",
    "print(\"num features\", data.num_features)\n",
    "print(\"is undirected\", data.is_undirected())\n",
    "print(\"is directed\", data.is_directed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots for data visualization and exploration\n",
    "# G = to_networkx(data, to_undirected=True)\n",
    "# pos = nx.spring_layout(G)\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# nx.draw(G, pos, node_size=10, width=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(data, train_ratio, val_ratio):\n",
    "  num_nodes = data.num_nodes\n",
    "  indices = list(range(num_nodes))\n",
    "  np.random.shuffle(indices)\n",
    "  \n",
    "  # Create masks\n",
    "  train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "  val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "  test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "  \n",
    "  # Set proportions for train, val, and test\n",
    "  train_end = int(train_ratio * num_nodes)\n",
    "  val_end = train_end + int(val_ratio * num_nodes)\n",
    "  train_mask[indices[:train_end]] = True\n",
    "  val_mask[indices[train_end:val_end]] = True\n",
    "  test_mask[indices[val_end:]] = True\n",
    "  \n",
    "  # Assign the custom masks to the dataset\n",
    "  data.train_mask = train_mask\n",
    "  data.val_mask = val_mask\n",
    "  data.test_mask = test_mask\n",
    "\n",
    "\n",
    "def train_test_split_graph(data: Data, train_ratio: float, val_ratio: float, batch_size: int):\n",
    "    \"\"\"\n",
    "    Split the graph data into train, validation, and test sets\n",
    "    :param data: The graph data\n",
    "    :param train_ratio: The ratio of the training set\n",
    "    :param val_ratio: The ratio of the validation set\n",
    "    :param batch_size: The batch size\n",
    "    \n",
    "    :return: The train, validation, and test data loaders\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the function to create masks\n",
    "    create_masks(data, train_ratio, val_ratio)\n",
    "\n",
    "    # train, validation, and test node indices based on the masks\n",
    "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
    "    val_idx = data.val_mask.nonzero(as_tuple=False).view(-1)\n",
    "    test_idx = data.test_mask.nonzero(as_tuple=False).view(-1)\n",
    "    \n",
    "    def create_data_loader(data, indices):\n",
    "        return DataLoader(data[indices], batch_size=batch_size, shuffle=True)\n",
    "      \n",
    "    def create_neighbor_loader(data, indices, batch_size=batch_size):\n",
    "        return NeighborLoader(data, num_neighbors=[30] * 2, batch_size=batch_size, input_nodes=indices)\n",
    "\n",
    "    # create the data loaders\n",
    "    train_loader = create_neighbor_loader(data, train_idx)\n",
    "    val_loader = create_neighbor_loader(data, val_idx, batch_size=4096*2)\n",
    "    test_loader = create_neighbor_loader(data, test_idx)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, data_loader, device, data):\n",
    "    \"\"\"Train the model for one epoch using NeighborSampler mini-batches.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_size, n_id, adjs in data_loader:\n",
    "        # `n_id` includes target nodes and all sampled neighbors in this mini-batch\n",
    "        # `batch_size` is the number of target nodes for which loss should be calculated\n",
    "\n",
    "        adjs = [adj.to(device) for adj in adjs]  # Move sampled adjacency matrices to GPU\n",
    "\n",
    "        # Move input features of all nodes in `n_id` to the device\n",
    "        x_input = data.x[n_id].to(device)\n",
    "        \n",
    "        # Compute the model's predictions for the mini-batch\n",
    "        out = model(x_input, adjs[0].edge_index)\n",
    "        \n",
    "        # Calculate loss only for the first `batch_size` target nodes\n",
    "        loss = F.nll_loss(out[:batch_size], data.y[n_id[:batch_size]].to(device))\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data_loader, device, data):\n",
    "    \"\"\"Evaluate the model on the validation or test set using NeighborSampler mini-batches.\"\"\"\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch_size, n_id, adjs in data_loader:\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "        \n",
    "        # Compute predictions for all nodes in the mini-batch\n",
    "        x_input = data.x[n_id].to(device)\n",
    "        out = model(x_input, adjs[0].edge_index)\n",
    "\n",
    "        # Get predictions only for the first `batch_size` target nodes\n",
    "        pred = out[:batch_size].max(dim=1)[1]\n",
    "        \n",
    "        # Compare with the actual labels of the target nodes\n",
    "        total_correct += (pred == data.y[n_id[:batch_size]].to(device)).sum().item()\n",
    "\n",
    "    # Calculate accuracy based on the number of target nodes in the entire set\n",
    "    return total_correct / len(data_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    correct = (predictions.argmax(dim=1) == labels).sum().item()\n",
    "    total = labels.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def f1(predictions, labels):\n",
    "    preds = predictions.argmax(dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    return f1_score(labels, preds, average='weighted')\n",
    "  \n",
    "def balanced_accuracy(predictions, labels):\n",
    "    preds = predictions.argmax(dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    return balanced_accuracy_score(labels, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, loss_fn, train_loader, device, metrics):\n",
    "    model.train()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    losses = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        out, h = model(batch.x, batch.edge_index)  # Receive only one output\n",
    "        loss = loss_fn(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        all_preds.append(out.detach().cpu())\n",
    "        all_labels.append(batch.y.detach().cpu())\n",
    "        \n",
    "    # Concatenate all predictions and labels\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Compute metrics on the entire dataset\n",
    "    avg_metrics = {metric_name: metric_fn(all_preds, all_labels) \n",
    "                  for metric_name, metric_fn in metrics.items()}\n",
    "    avg_loss = np.mean(losses)\n",
    "\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loss_fn, val_loader, device, metrics):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    losses = []\n",
    "\n",
    "    for batch in val_loader:\n",
    "        batch = batch.to(device)\n",
    "        out, h = model(batch.x, batch.edge_index)  # Receive only one output\n",
    "        loss = loss_fn(out, batch.y)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        all_preds.append(out.detach().cpu())\n",
    "        all_labels.append(batch.y.detach().cpu())\n",
    "        \n",
    "    # with torch.no_grad():\n",
    "    #   _, h = model(val_loader.data.x, val_loader.data.edge_index)\n",
    "    #   visualize(h, val_loader.data.y)\n",
    "\n",
    "    # Concatenate all predictions and labels\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Compute metrics on the entire dataset\n",
    "    avg_metrics = {metric_name: metric_fn(all_preds, all_labels) \n",
    "                  for metric_name, metric_fn in metrics.items()}\n",
    "    avg_loss = np.mean(losses)\n",
    "\n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "def training_loop(model, optimizer, loss_fn, train_loader, val_loader, num_epochs, device, metrics):\n",
    "    print(\"Starting training\")\n",
    "    train_losses, val_losses = [], []\n",
    "    train_metrics_history = {metric_name: [] for metric_name in metrics}\n",
    "    val_metrics_history = {metric_name: [] for metric_name in metrics}\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Training\n",
    "        train_loss, train_metrics = train_epoch(\n",
    "            model, optimizer, loss_fn, train_loader, device, metrics)\n",
    "        # Validation\n",
    "        val_loss, val_metrics = validate(\n",
    "            model, loss_fn, val_loader, device, metrics)\n",
    "        \n",
    "        # Logging results\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        for metric_name in metrics:\n",
    "            train_metrics_history[metric_name].append(train_metrics[metric_name])\n",
    "            val_metrics_history[metric_name].append(val_metrics[metric_name])\n",
    "\n",
    "        # Print metrics\n",
    "        metrics_str = ', '.join(\n",
    "            [f'{metric_name}: {train_metrics[metric_name]:.3f} (train), {val_metrics[metric_name]:.3f} (val)'\n",
    "             for metric_name in metrics])\n",
    "        print(\n",
    "            f\"Epoch {epoch}/{num_epochs}: \"\n",
    "            f\"Loss: {train_loss:.3f} (train), {val_loss:.3f} (val), \"\n",
    "            f\"{metrics_str}\"\n",
    "        )\n",
    "\n",
    "    return model, train_losses, val_losses, train_metrics_history, val_metrics_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "learning_rate = 0.01  \n",
    "batch_size = 64\n",
    "  \n",
    "train_loader, val_loader, test_loader = train_test_split_graph(\n",
    "      data, train_ratio, val_ratio, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_experiment(model, train_loader, val_loader):\n",
    "  print(model.__class__.__name__)\n",
    "  \n",
    "  optimizer = torch.optim.Adam(\n",
    "      model.parameters(), lr=learning_rate)\n",
    "  \n",
    "  loss_fn = torch.nn.CrossEntropyLoss()\n",
    "  \n",
    "  metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'f1': f1,\n",
    "    'balanced_accuracy': balanced_accuracy,\n",
    "  }\n",
    "  \n",
    "  # Train the model\n",
    "  model, train_losses, val_losses, train_metrics_history, val_metrics_history = training_loop(\n",
    "    model, optimizer, loss_fn, train_loader, val_loader, num_epochs=10, device=device, metrics=metrics\n",
    "  )\n",
    "  \n",
    "  return {\n",
    "    'model': model,\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_metrics_history': train_metrics_history,\n",
    "    'val_metrics_history': val_metrics_history\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes).to(device)\n",
    "gat = GAT(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes, num_heads=8)\n",
    "gin = GIN(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes)\n",
    "gsage = GraphSAGE(in_channels=data.num_node_features, hidden_channels=64, out_channels=data.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "gcn_results = gnn_experiment(gcn, train_loader, val_loader)\n",
    "#gnn_experiment(gsage, train_loader, val_loader)\n",
    "\n",
    "#save gcn_results_benchmark as pt\n",
    "torch.save(gcn_results, 'gcn_results_benchmark.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gat_results = gnn_experiment(gat, train_loader, val_loader)\n",
    "#save gat_results_benchmark as pt\n",
    "torch.save(gat_results, 'gat_results_benchmark.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rigged",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
